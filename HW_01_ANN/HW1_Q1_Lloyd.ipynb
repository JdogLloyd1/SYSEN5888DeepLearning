{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2827fa83",
   "metadata": {},
   "source": [
    "SYSEN 5888 Spring 2026\n",
    "\n",
    "Jonathan Lloyd\n",
    "\n",
    "Homework 1, Question 1\n",
    "\n",
    "\n",
    "Goal: Build and train an artificial neural network for a binary classification task. \n",
    "\n",
    "Tools: Pytorch\n",
    "\n",
    "Data: The input data and their corresponding binary labels are provided in the data file, hw1data.dat\n",
    "The input data contains 1000 two-dimensional data points that lie within a square of area one. The input data and labels should be loaded by reading the data file using any choice of library. Please note that for binary classification, the -1/1 labels need to be converted into 0/1 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff4b273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import data file\n",
    "# Pull in hw1data.dat (path relative to notebook: go up to project root, then into HW_01_ANN)\n",
    "hw1data = np.loadtxt('../HW_01_ANN/hw1data.dat')\n",
    "\n",
    "# Convert labels to 0/1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c96ccd",
   "metadata": {},
   "source": [
    "Architecture: Define a Sequential model, wherein the layers are stacked sequentially and each layer has exactly one input tensor and one output tensor. Please build an artificial neural network by adding the following layers to the Sequential model using the configuration below.\n",
    "- Input - Shape 2\n",
    "- Dense - Units 5\n",
    "- Dense - Units 1 - Activation Sigmoid\n",
    "\n",
    "The initial random weights of layers can be defined by specifying weight and bias initializers. For each of the above layers, initialize the kernel weights from a Xavier/Glorot uniform distribution and set the random seed to 99. Additionally, initialize the bias vector as a zero vector. The activation function defines the node output given a set of inputs. An appropriate choice of activation function is required to allow the artificial neural network to learn a non-linear pattern. The activation functions for the first dense layer can be chosen from some of the commonly used activation functions like Rectified Linear Unit (ReLU), Hyperbolic Tangent (tanh), and Sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc78a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Network Layers\n",
    "\n",
    "\n",
    "# Initialize Weights and Biases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd0a8de",
   "metadata": {},
   "source": [
    "Training: The model is compiled by specifying the optimizer, the loss function and metrics to be recorded at each step of the training process. For binary classification, it is a common practice to use binary cross-entropy as loss function. Popular deep learning libraries provide support for several optimization algorithms. Some of them are Stochastic gradient descent (SGD), RMSprop, ADAM. Please choose accuracy as a metric during model compilation. Finally, train the artificial neural network by fitting the input data and labels with each of the aforementioned optimizers and their respective configuration as given in the table below. The neural network should be trained until convergence is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74566610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "\n",
    "# Define Metrics\n",
    "\n",
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37235eb2",
   "metadata": {},
   "source": [
    "Deliverables: Please report the training accuracy after the training process is carried out for *every combination* of activation function and optimizer.\n",
    "Plot the loss curves to determine the number of epochs required to achieve convergence.\n",
    "Report the hyperparameter tuning step.\n",
    "Predict and report the binary classification results for the data point [0.8, 0.2] with the trained artificial neural network.\n",
    "Discuss the influence of particular parameters on different optimizers.\n",
    "It is recommended that the final results be reported in a tabular format as shown below. Please also make sure to submit your working code files along with the final results.\n",
    "\n",
    "| Optimizer                                                                                                                                           | Activation function | Required epochs | Training accuracy (%) | Prediction for [0.8, 0.2] |\n",
    "| --------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------- | --------------- | --------------------- | ------------------------- |\n",
    "| SGD (Learning rate = 0.01, Momentum = [0.0, 0.1, 0.5, 0.9], discuss the impact of momentum values on the convergence behavior of the SGD optimizer) | ReLU                |                 |                       |                           |\n",
    "| SGD (Learning rate = 0.01, Momentum = [0.0, 0.1, 0.5, 0.9], discuss the impact of momentum values on the convergence behavior of the SGD optimizer) | Tanh                |                 |                       |                           |\n",
    "| SGD (Learning rate = 0.01, Momentum = [0.0, 0.1, 0.5, 0.9], discuss the impact of momentum values on the convergence behavior of the SGD optimizer) | Sigmoid             |                 |                       |                           |\n",
    "| RMSprop (Learning rate = [0.0001, 0.001, 0.01], discuss the effect of learning rates on learning curves, Epsilon = 10^-6)                           | ReLU                |                 |                       |                           |\n",
    "| RMSprop (Learning rate = [0.0001, 0.001, 0.01], discuss the effect of learning rates on learning curves, Epsilon = 10^-6)                           | Tanh                |                 |                       |                           |\n",
    "| RMSprop (Learning rate = [0.0001, 0.001, 0.01], discuss the effect of learning rates on learning curves, Epsilon = 10^-6)                           | Sigmoid             |                 |                       |                           |\n",
    "| ADAM (β₁=[0.85, 0.9], β₂=[0.95, 0.99], discuss the functions of the parameters β₁ and β₂)                                                           | ReLU                |                 |                       |                           |\n",
    "| ADAM (β₁=[0.85, 0.9], β₂=[0.95, 0.99], discuss the functions of the parameters β₁ and β₂)                                                           | Tanh                |                 |                       |                           |\n",
    "| ADAM (β₁=[0.85, 0.9], β₂=[0.95, 0.99], discuss the functions of the parameters β₁ and β₂)                                                           | Sigmoid             |                 |                       |                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3403993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss Curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and Report Results Table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd878524",
   "metadata": {},
   "source": [
    "Discussion Section\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
