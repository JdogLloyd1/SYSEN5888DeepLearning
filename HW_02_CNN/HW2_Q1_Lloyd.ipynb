{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b02aba61",
      "metadata": {
        "id": "b02aba61"
      },
      "source": [
        "SYSEN 5888 Spring 2026\n",
        "\n",
        "Jonathan Lloyd\n",
        "\n",
        "Homework 2, Question 1\n",
        "\n",
        "\n",
        "Goal: Building a convolutional neural network (ConvNet) to classify images of fruits and vegetables into their respective classes\n",
        "\n",
        "Tools: Numpy, PyTorch, Torchvision\n",
        "\n",
        "Data: Fruits-360 on Kaggle https://www.kaggle.com/moltean/fruits\n",
        "\n",
        "Task: Load dataset, scale 100x100 images to 75x75, normalization and data augmentation, define training and testing datasets (85%/15% split), batch each dataset into sizes 1000, shuffle seed 42, define sequential ConvNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c3ccab48",
      "metadata": {
        "id": "c3ccab48",
        "outputId": "9670f567-c54a-4dd8-bcf6-1255dadf7883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport subprocess\\nresult = subprocess.run([\\'nvidia-smi\\'], capture_output=True, text=True)\\nprint(result.stdout if result.returncode == 0 else \"No GPU detected (CPU runtime)\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Check Colab Server details if running outside of Colab Online UI\n",
        "'''\n",
        "import subprocess\n",
        "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "print(result.stdout if result.returncode == 0 else \"No GPU detected (CPU runtime)\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ff591cd9",
      "metadata": {
        "id": "ff591cd9"
      },
      "outputs": [],
      "source": [
        "## IMPORT API KEY - UNCOMMENT APPLICABLE LINES WHEN RUNNING DIFFERENT KERNELS\n",
        "# Import KAGGLE_API_KEY from .env\n",
        "# KAGGLE_API_TOKEN = os.getenv(\"KAGGLE_API_KEY\")\n",
        "# Define directly - delete key before uploading to GitHub\n",
        "# KAGGLE_API_TOKEN =\n",
        "# When running in Colab - define in web using Colab Secrets\n",
        "# KAGGLE_API_TOKEN = userdata.get(\"KAGGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ee068ae6",
      "metadata": {
        "id": "ee068ae6",
        "outputId": "e76f5a4d-96ab-4930-d930-fbb855c50c07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting pandas\n",
            "  Downloading pandas-3.0.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Collecting kagglehub\n",
            "  Downloading kagglehub-1.0.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.10.0+cu128)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.25.0+cu128)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.12/dist-packages (7.34.0)\n",
            "Collecting IPython\n",
            "  Downloading ipython-9.10.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Collecting kagglesdk<1.0,>=0.1.14 (from kagglehub)\n",
            "  Downloading kagglesdk-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (26.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.24.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch) (1.3.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: decorator>=4.3.2 in /usr/local/lib/python3.12/dist-packages (from IPython) (4.4.2)\n",
            "Collecting ipython-pygments-lexers>=1.0.0 (from IPython)\n",
            "  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting jedi>=0.18.1 (from IPython)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from IPython) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from IPython) (4.9.0)\n",
            "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.12/dist-packages (from IPython) (3.0.52)\n",
            "Requirement already satisfied: pygments>=2.11.0 in /usr/local/lib/python3.12/dist-packages (from IPython) (2.19.2)\n",
            "Collecting stack_data>=0.6.0 (from IPython)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting traitlets>=5.13.0 (from IPython)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.18.1->IPython) (0.8.6)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kagglesdk<1.0,>=0.1.14->kagglehub) (5.29.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting executing>=1.2.0 (from stack_data>=0.6.0->IPython)\n",
            "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack_data>=0.6.0->IPython)\n",
            "  Downloading asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting pure-eval (from stack_data>=0.6.0->IPython)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2026.1.4)\n",
            "Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-3.0.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m139.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kagglehub-1.0.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython-9.10.0-py3-none-any.whl (622 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kagglesdk-0.1.15-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.4/160.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asttokens-3.0.1-py3-none-any.whl (27 kB)\n",
            "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pure-eval, traitlets, numpy, jedi, ipython-pygments-lexers, executing, asttokens, stack_data, pandas, kagglesdk, kagglehub, IPython\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: kagglehub\n",
            "    Found existing installation: kagglehub 0.3.13\n",
            "    Uninstalling kagglehub-0.3.13:\n",
            "      Successfully uninstalled kagglehub-0.3.13\n",
            "  Attempting uninstall: IPython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 9.10.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 3.0.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.4.2 which is incompatible.\n",
            "db-dtypes 1.5.0 requires pandas<3.0.0,>=1.5.3, but you have pandas 3.0.1 which is incompatible.\n",
            "cudf-cu12 26.2.1 requires pandas<2.4.0,>=2.0, but you have pandas 3.0.1 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.4.2 which is incompatible.\n",
            "bqplot 0.12.45 requires pandas<3.0.0,>=1.0.0, but you have pandas 3.0.1 which is incompatible.\n",
            "dask-cudf-cu12 26.2.1 requires pandas<2.4.0,>=2.0, but you have pandas 3.0.1 which is incompatible.\n",
            "gradio 5.50.0 requires pandas<3.0,>=1.0, but you have pandas 3.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed IPython-9.10.0 asttokens-3.0.1 executing-2.2.1 ipython-pygments-lexers-1.1.1 jedi-0.19.2 kagglehub-1.0.0 kagglesdk-0.1.15 numpy-2.4.2 pandas-3.0.1 pure-eval-0.2.3 stack_data-0.6.3 traitlets-5.14.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "traitlets"
                ]
              },
              "id": "e2ec0e17f11d42b4a5e5ecb99fbb25fd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# update any packages in Colab server\n",
        "%pip install --upgrade numpy pandas kagglehub torch torchvision IPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8f9b5a86",
      "metadata": {
        "id": "8f9b5a86",
        "outputId": "3129f24b-6414-421b-d012-4707845ecb33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-752/2175186048.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticDepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_presets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgiou_loss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneralized_box_iou_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrozenBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSqueezeExcitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/ops/roi_align.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_compile_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBroadcastingList2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0maot_compile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/aot_compile.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_frame\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphRuntimeEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_graph_device_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSystemInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackTrigger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_compile_pg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_convert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorifyState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompileId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructured\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/symbolic_convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mObservedException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorifyScalarRestartAnalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guards\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracingContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdump_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/exc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcounters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbolic_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/experimental/symbolic_shapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msympy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msympy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sympy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmpmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     raise ImportError(\"SymPy now depends on mpmath as an external library. \"\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mpmath/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0musertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtiming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mctx_fp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFPContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mctx_mp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mctx_iv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPIntervalContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mpmath/ctx_fp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mctx_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardBaseContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mpmath/ctx_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moperator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlibmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpecialFunctions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mpmath/libmp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m   mpf_acos, mpf_asinh, mpf_acosh, mpf_atanh, mpf_fibonacci)\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m from .libhyper import (NoConvergence, make_hyp_summator,\n\u001b[0m\u001b[1;32m     41\u001b[0m   \u001b[0mmpf_erf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpf_erfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpf_ei\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpc_ei\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpf_e1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpc_e1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpf_expint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0mmpf_ci_si\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpf_ci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpf_si\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpc_ci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpc_si\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpf_besseljn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mpmath/libmp/libhyper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlibintmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mifac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgammazeta\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmpf_gamma_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpf_euler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuler_fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNoConvergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Import dataset from Kaggle\n",
        "# Kagglehub reads KAGGLE_API_TOKEN from environment (set in cell above)\n",
        "os.environ[\"KAGGLE_API_TOKEN\"] = KAGGLE_API_TOKEN\n",
        "# On Colab: use /content to avoid cache disk limits; locally omit output_dir to use cache\n",
        "path = kagglehub.dataset_download(\"moltean/fruits\", output_dir=\"/content/fruits-360\")\n",
        "\n",
        "# Locate Training and Test subfolders (Fruits-360 dataset structure)\n",
        "path = Path(path)\n",
        "# Kaggle zip may nest Training/Test inside a subfolder (e.g. fruits-360/Training)\n",
        "# Search recursively for Training directory\n",
        "train_path = None\n",
        "for p in path.rglob(\"Training\"):\n",
        "    if p.is_dir() and (p.parent / \"Test\").exists():\n",
        "        train_path = p\n",
        "        break\n",
        "if train_path is not None:\n",
        "    test_path = train_path.parent / \"Test\"\n",
        "else:\n",
        "    # Fallback: check direct children\n",
        "    if (path / \"Training\").exists():\n",
        "        train_path, test_path = path / \"Training\", path / \"Test\"\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Could not find Training/Test folders. Dataset root: {path}\\n\"\n",
        "            f\"Contents: {[d.name for d in path.iterdir()] if path.exists() else 'path does not exist'}\"\n",
        "        )\n",
        "\n",
        "# Load image datasets with placeholder transform (will add scaling/normalization in next steps)\n",
        "print(\"Loading datasets\")\n",
        "train_dataset = torchvision.datasets.ImageFolder(str(train_path), transform=transforms.ToTensor())\n",
        "test_dataset = torchvision.datasets.ImageFolder(str(test_path), transform=transforms.ToTensor())\n",
        "\n",
        "print(f\"Dataset downloaded to: {path}\")\n",
        "print(f\"Training samples: {len(train_dataset)} | Classes: {len(train_dataset.classes)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c8b1ba",
      "metadata": {
        "id": "57c8b1ba"
      },
      "outputs": [],
      "source": [
        "## Image Preprocessing\n",
        "\n",
        "# 1. Image scaling (100x100 -> 75x75):\n",
        "image_size = 75\n",
        "\n",
        "# 2. Image normalization values for RGB to [-1, 1]\n",
        "normalize_means = [0.5, 0.5, 0.5]\n",
        "normalize_stds = [0.5, 0.5, 0.5]\n",
        "\n",
        "# 3. Data augmentation and normalization for training; only normalization for validation/test\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=normalize_means, std=normalize_stds)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=normalize_means, std=normalize_stds)\n",
        "])\n",
        "\n",
        "# Replace raw datasets with transformed datasets\n",
        "train_dataset = torchvision.datasets.ImageFolder(str(train_path), transform=train_transform)\n",
        "test_dataset = torchvision.datasets.ImageFolder(str(test_path), transform=test_transform)\n",
        "\n",
        "# 4. Define training and validation split (85%/15% from train_dataset)\n",
        "total_train = len(train_dataset)\n",
        "val_size = int(0.15 * total_train)\n",
        "train_size = total_train - val_size\n",
        "\n",
        "SHUFFLE_SEED = 42\n",
        "torch.manual_seed(SHUFFLE_SEED)  # set random seed for reproducibility\n",
        "train_subset, val_subset = random_split(train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(SHUFFLE_SEED))\n",
        "\n",
        "# 5. Define dataloaders with batch size 1000 and consistent shuffle with seed\n",
        "batch_size = 1000\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, worker_init_fn=lambda worker_id: np.random.seed(SHUFFLE_SEED))\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "print(\"Loading success\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b35609e4",
      "metadata": {
        "id": "b35609e4"
      },
      "source": [
        "Architecture - MODEL 1:\n",
        "\n",
        "Define a Sequential model, wherein the layers are stacked sequentially and each layer has exactly one input tensor and one output tensor. Please build a ConvNet by adding the layers to the Sequential model using the configuration below. For each of the layers, initialize the kernel weights from a Glorot uniform distribution and set the random seed to 99. Additionally, initialize the bias vector as a zero vector. In this architecture, you may use different dropout values [0.1, 0.3, 0.5] and report the impact of dropout values on model performance.\n",
        "![alt text](<model 1 arch.png>)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b1f22d3",
      "metadata": {
        "id": "1b1f22d3"
      },
      "outputs": [],
      "source": [
        "# Model 1: per architecture table (2 conv layers, BatchNorm, Dropout [0.1, 0.3, 0.5], Dense 256 -> 251).\n",
        "# Assumes input size 75x75; Glorot uniform, zero bias, seed 99.\n",
        "NUM_CLASSES = 251\n",
        "\n",
        "class Model1(nn.Module):\n",
        "    # Sequential ConvNet: Conv2D(64)->ReLU->MaxPool, Conv2D(128)->ReLU->BN->Dropout->MaxPool, Flatten->Dense(256)->ReLU->Dense(251).\n",
        "    # NOTE: forward() returns raw logits (no softmax). This is the recommended PyTorch pattern when\n",
        "    # using nn.CrossEntropyLoss, which internally applies log-softmax. Apply torch.softmax(logits, dim=1)\n",
        "    # at inference time only if you need class probabilities.\n",
        "    def __init__(self, num_classes=251, dropout=0.1, in_channels=3, input_h=75, input_w=75):\n",
        "        super(Model1, self).__init__()\n",
        "        # Layer 1–2: Conv2D 64, (3,3), no padding, ReLU; MaxPool2D (2,2)\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=0)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        # Layer 3–6: Conv2D 128, (3,3), no padding, ReLU; BatchNorm; Dropout; MaxPool2D (2,2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(128, eps=0.001, momentum=0.01)  # 0.01 in PyTorch = 0.99 in Keras (weight on running stats)\n",
        "        self.drop2 = nn.Dropout2d(p=dropout)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        # Layer 7–9: Flatten; Dense 256 ReLU; Dense 251\n",
        "        self.flatten = nn.Flatten()\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, in_channels, input_h, input_w)\n",
        "            dummy = self.pool2(self.drop2(self.bn2(self.relu2(self.conv2(self.pool1(self.relu1(self.conv1(dummy))))))))\n",
        "            flat_size = self.flatten(dummy).shape[1]\n",
        "        self.fc1 = nn.Linear(flat_size, 256)\n",
        "        self.relu_fc = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.relu2(self.conv2(x))\n",
        "        x = self.bn2(x)\n",
        "        x = self.drop2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu_fc(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def _init_weights_biases(self):\n",
        "        torch.manual_seed(99)\n",
        "        for m in [self.conv1, self.conv2, self.fc1, self.fc2]:\n",
        "            if hasattr(m, \"weight\") and m.weight is not None:\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "            if hasattr(m, \"bias\") and m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ef88fe5",
      "metadata": {
        "id": "3ef88fe5"
      },
      "source": [
        "Architecture - MODEL 2:\n",
        "\n",
        "The performance of the CNN model is notably impacted by the number of convolutional layers it employs. In the preceding design, two convolutional layers were integrated. Kindly introduce an additional convolutional layer (as depicted in the updated architecture below) and elaborate on the roles of convolutional layers.\n",
        "![alt text](<model 2 arch.png>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0257bffc",
      "metadata": {
        "id": "0257bffc"
      },
      "outputs": [],
      "source": [
        "# Model 2: per architecture table (3 conv layers 64->128->256, BatchNorm, Dropout 0.3, Dense 512->251).\n",
        "class Model2(nn.Module):\n",
        "    # Sequential ConvNet per table: Conv(64)->ReLU->Pool, Conv(128)->ReLU->Pool, Conv(256)->ReLU->BN->Dropout(0.3)->Pool, Flatten->Dense(512)->ReLU->Dense(251).\n",
        "    # NOTE: forward() returns raw logits (no softmax). Use nn.CrossEntropyLoss during training; apply\n",
        "    # torch.softmax(logits, dim=1) at inference time only when probabilities are needed.\n",
        "    def __init__(self, num_classes=251, dropout=0.3, in_channels=3, input_h=75, input_w=75):\n",
        "        super(Model2, self).__init__()\n",
        "        # Layers 1–2: Conv2D 64, (3,3), no padding, ReLU; MaxPool2D (2,2)\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=0)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        # Layers 3–4: Conv2D 128, (3,3), no padding, ReLU; MaxPool2D (2,2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        # Layers 5–8: Conv2D 256, (3,3), no padding, ReLU; BatchNorm; Dropout 0.3; MaxPool2D (2,2)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=0)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.bn3 = nn.BatchNorm2d(256, eps=0.001, momentum=0.01)  # 0.01 in PyTorch = 0.99 in Keras (weight on running stats)\n",
        "        self.drop3 = nn.Dropout2d(p=dropout)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        # Layers 9–11: Flatten; Dense 512 ReLU; Dense 251\n",
        "        self.flatten = nn.Flatten()\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, in_channels, input_h, input_w)\n",
        "            dummy = self.pool1(self.relu1(self.conv1(dummy)))\n",
        "            dummy = self.pool2(self.relu2(self.conv2(dummy)))\n",
        "            dummy = self.pool3(self.drop3(self.bn3(self.relu3(self.conv3(dummy)))))\n",
        "            flat_size = self.flatten(dummy).shape[1]\n",
        "        self.fc1 = nn.Linear(flat_size, 512)\n",
        "        self.relu_fc = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.relu3(self.conv3(x))\n",
        "        x = self.bn3(x)\n",
        "        x = self.drop3(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu_fc(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def _init_weights_biases(self):\n",
        "        torch.manual_seed(99)\n",
        "        for m in [self.conv1, self.conv2, self.conv3, self.fc1, self.fc2]:\n",
        "            if hasattr(m, \"weight\") and m.weight is not None:\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "            if hasattr(m, \"bias\") and m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c947bbbc",
      "metadata": {
        "id": "c947bbbc"
      },
      "source": [
        "Training: The model is compiled by specifying the optimizer, the loss function and metrics to be recorded at each step of the training process. The ADAM optimizer should minimize the categorical cross entropy. The ConvNet model can be trained and evaluated with the previously created data generators. The training step size can be calculated by dividing the number of images in the generator with the batch size for training and testing data, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18670b1a",
      "metadata": {
        "id": "18670b1a"
      },
      "outputs": [],
      "source": [
        "# Define data storage\n",
        "results_dataframe = pd.DataFrame(columns=[\n",
        "    'Model Name', 'Dropout', 'Epochs', 'Training Accuracy (%)',\n",
        "    'Validation Accuracy (%)', 'Test Accuracy (%)', 'Final Test Loss'\n",
        "])\n",
        "\n",
        "# Maximum epochs to run training\n",
        "# Start with 50, go down to 20 if too time consuming\n",
        "MAX_EPOCHS = 50\n",
        "\n",
        "## Helper Functions\n",
        "\n",
        "# BASIC TRAIN\n",
        "def train(model, loader, criterion, optimizer):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch.\n",
        "\n",
        "    Parameters:\n",
        "        model (nn.Module): The neural network model.\n",
        "        loader (DataLoader): DataLoader for training data.\n",
        "        criterion: Loss function.\n",
        "        optimizer: Optimization algorithm.\n",
        "        device: Device to run the training on.\n",
        "\n",
        "    Returns:\n",
        "        epoch_loss (float): Average loss for the epoch.\n",
        "        epoch_acc (float): Accuracy for the epoch.\n",
        "    \"\"\"\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the parameter gradients\n",
        "\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Optimize\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)  # Accumulate loss\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# BASIC EVAL\n",
        "def evaluate(model, loader, criterion):\n",
        "    # Compute 3 accuracy percentages\n",
        "    \"\"\"\n",
        "    Evaluate the model on validation or test data.\n",
        "\n",
        "    Parameters:\n",
        "        model (nn.Module): The neural network model.\n",
        "        loader (DataLoader): DataLoader for validation/test data.\n",
        "        criterion: Loss function.\n",
        "\n",
        "    Returns:\n",
        "        epoch_loss (float): Average loss for the epoch.\n",
        "        epoch_acc (float): Accuracy for the epoch.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for inputs, labels in loader:\n",
        "\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute loss\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)  # Accumulate loss\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# PLOT LOSS CURVES\n",
        "def plot_loss(curve, dropout, dataset):\n",
        "    # Plot and save loss curve\n",
        "    # dataset = [Training, Validation]\n",
        "    output_dir = \"Plot JPGs\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(curve)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    if dataset == 'Training':\n",
        "        plt.ylabel(\"Training Loss\")\n",
        "    elif dataset == 'Validation':\n",
        "        plt.ylabel(\"Validation Loss\")\n",
        "\n",
        "    plt.title(f\"Categorical Cross Entropy Loss Curve for {dataset} Dataset, Dropout {dropout}\")\n",
        "    filename = f\"{output_dir}/LossCurve_{dataset}_Dataset_{dropout}_Dropout.jpg\"\n",
        "\n",
        "    plt.savefig(filename)\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cd458c3",
      "metadata": {
        "id": "3cd458c3"
      },
      "outputs": [],
      "source": [
        "# MODEL TRAIN\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=50):\n",
        "    \"\"\"\n",
        "    Train the model and evaluate on test data after each epoch.\n",
        "\n",
        "    Parameters:\n",
        "        model (nn.Module): The neural network model.\n",
        "        train_loader (DataLoader): DataLoader for training data.\n",
        "        test_loader (DataLoader): DataLoader for test data.\n",
        "        criterion: Loss function.\n",
        "        optimizer: Optimization algorithm.\n",
        "        device: Device to run the training on.\n",
        "        num_epochs (int): Number of training epochs.\n",
        "\n",
        "    Returns:\n",
        "        Training and validation loss and accuracy.\n",
        "    \"\"\"\n",
        "    training_loss_curve = []\n",
        "    validation_loss_curve = []\n",
        "    training_accuracy = []\n",
        "    validation_accuracy = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train(model, train_loader, criterion, optimizer)\n",
        "        val_loss, val_acc = evaluate(model, test_loader, criterion)\n",
        "\n",
        "        training_loss_curve.append(train_loss)\n",
        "        training_accuracy.append(train_acc)\n",
        "        validation_loss_curve.append(val_loss)\n",
        "        validation_accuracy.append(val_acc)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} | '\n",
        "              f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | '\n",
        "              f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
        "\n",
        "    return training_loss_curve, validation_loss_curve, training_accuracy, validation_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2ae7e07",
      "metadata": {
        "id": "c2ae7e07"
      },
      "outputs": [],
      "source": [
        "# MAIN EXPERIMENT HELPER\n",
        "def run_experiment(model_arch, train_loader, val_loader, test_loader, max_epochs=50, dropout=None):\n",
        "    # Run full experiment: instantiate model, train, evaluate accuracies, plot, return results to dataframe\n",
        "    if model_arch == 1:\n",
        "        model = Model1(dropout=dropout)\n",
        "    elif model_arch == 2:\n",
        "        model = Model2() # dropout = 0.3 by default\n",
        "    else:\n",
        "        raise ValueError(f\"ERROR: Model selected {model_arch} does not match possible options (1, 2).\")\n",
        "\n",
        "    # Define Optimizer\n",
        "    # Adam, Categorical Cross Entropy\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    # Train\n",
        "    training_loss_curve, validation_loss_curve, training_accuracy, validation_accuracy = train_model(\n",
        "        model, train_loader, val_loader, criterion, optimizer, max_epochs\n",
        "    )\n",
        "\n",
        "    # Evaluate final test\n",
        "    final_test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
        "\n",
        "    # Save plots\n",
        "    plot_loss(training_loss_curve, dropout, \"Training\")\n",
        "    plot_loss(validation_loss_curve, dropout, \"Validation\")\n",
        "\n",
        "    # return results\n",
        "    row = {\n",
        "        'Model Name': f\"Model {model_arch}\",\n",
        "        'Dropout': dropout,\n",
        "        'Epochs': max_epochs,\n",
        "        'Training Accuracy (%)': training_accuracy[-1] * 100.0,\n",
        "        'Validation Accuracy (%)': validation_accuracy[-1] * 100.0,\n",
        "        'Test Accuracy (%)': test_acc * 100.0,\n",
        "        'Final Test Loss': final_test_loss\n",
        "    }\n",
        "\n",
        "    return row\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1004a046",
      "metadata": {
        "id": "1004a046"
      },
      "outputs": [],
      "source": [
        "# Train and Test Model 1a, 1b, 1c\n",
        "# For loop to pass different dropouts\n",
        "DROPOUT_SELECTOR = [0.1, 0.3, 0.5]\n",
        "for d in DROPOUT_SELECTOR:\n",
        "    print(f\"RUNNING MODEL 1, DROPOUT {d}\")\n",
        "    model_run = run_experiment(1, train_loader, val_loader, test_loader, max_epochs=MAX_EPOCHS, dropout=d)\n",
        "    results_dataframe = pd.concat([results_dataframe, pd.DataFrame([model_run])], ignore_index=True)\n",
        "    print(f\"COMPLETED MODEL 1, DROPOUT {d}\")\n",
        "\n",
        "# Train and Test Model 2, no dropout arg\n",
        "print(f\"RUNNING MODEL 2\")\n",
        "model_run_2 = run_experiment(2, train_loader, val_loader, test_loader, max_epochs=MAX_EPOCHS)\n",
        "results_dataframe = pd.concat([results_dataframe, pd.DataFrame([model_run_2])], ignore_index=True)\n",
        "print(f\"COMPLETED MODEL 2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d639a945",
      "metadata": {
        "id": "d639a945"
      },
      "source": [
        "Deliverables: Please report the training and validation accuracy after the training process is carried out for 50 epochs (you can train for 20 epochs if the training is time consuming), in addition to the achieved accuracy levels on the test dataset. Also, plot the loss curves for both training and validation datasets. Discuss the functions of dropout values and the number of convolutional layers in relation to the CNN model performance. Please make sure to submit your working code files along with the final results and the plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "131a7be1",
      "metadata": {
        "id": "131a7be1"
      },
      "outputs": [],
      "source": [
        "# Print results dataframe\n",
        "print(results_dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a637878f",
      "metadata": {
        "id": "a637878f"
      },
      "outputs": [],
      "source": [
        "# Plot all loss curves together\n",
        "# Display the 3 Model 1 loss curve images together and Model 2 plot separately\n",
        "\n",
        "# Define subfolder and filenames\n",
        "plot_folder = \"HW_02_CNN/plots\"  # Adjust if your JPGs are in a different folder\n",
        "\n",
        "# Filenames for Model 1 plots\n",
        "model1_filenames = [\n",
        "    \"model1a_dropout_0.1_loss.jpg\",\n",
        "    \"model1b_dropout_0.3_loss.jpg\",\n",
        "    \"model1c_dropout_0.5_loss.jpg\"\n",
        "]\n",
        "# Filename for Model 2 plot (with dropout=0.3)\n",
        "model2_filename = \"model2_dropout_0.3_loss.jpg\"\n",
        "\n",
        "model1_titles = [\n",
        "    \"Model 1a (Dropout=0.1) Loss Curve\",\n",
        "    \"Model 1b (Dropout=0.3) Loss Curve\",\n",
        "    \"Model 1c (Dropout=0.5) Loss Curve\"\n",
        "]\n",
        "\n",
        "# Display Model 1 plots together\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
        "for idx, (fname, title) in enumerate(zip(model1_filenames, model1_titles)):\n",
        "    img_path = os.path.join(plot_folder, fname)\n",
        "    img = mpimg.imread(img_path)\n",
        "    ax = axs[idx]\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(title, fontsize=13)\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display Model 2 plot separately\n",
        "img_path2 = os.path.join(plot_folder, model2_filename)\n",
        "img2 = mpimg.imread(img_path2)\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.imshow(img2)\n",
        "plt.title(\"Model 2 (Dropout=0.3) Loss Curve\", fontsize=14)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8c5b225",
      "metadata": {
        "id": "b8c5b225"
      },
      "source": [
        "Discussion:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12f9826c",
      "metadata": {
        "id": "12f9826c"
      },
      "source": [
        "Bonus (+1): A skip connection in a neural network is a connection that skips one or more layers and connects to a later layer. Residual Networks (ResNets) have popularized the use of skip connections to address the vanishing gradient problem, and hence enabling the training of deeper networks. Your task for this bonus part is to integrate such a skip connection, any types of skip connections are acceptable. For instance, linking the output of the first layer convolutional directly to the input of the last convolutional layer in your model architecture. Based on your results, analyze and discuss any improvements or effects this change has on the model's performance"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}